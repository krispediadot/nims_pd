{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing_0516.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "so_Bbg2JEnxx"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Parkinson"
      ],
      "metadata": {
        "id": "5z-qe7YLE4Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "pd.options.display.max_rows = 100\n",
        "pd.options.display.max_columns = 50"
      ],
      "metadata": {
        "id": "1FmJ7zIYFFUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rawdata 저장 경로\n",
        "RAWDATAPATH = os.path.join(os.getcwd(), 'Rawdata')\n",
        "RAW_CONTROL = os.path.join(RAWDATAPATH , 'Controls')  # '/content/drive/MyDrive/Parkinson/Rawdata/Controls'\n",
        "RAW_PD = os.path.join(RAWDATAPATH, 'PD')              # '/content/drive/MyDrive/Parkinson/Rawdata/PD'\n",
        "\n",
        "\n",
        "# 추출 후 저장할 경로\n",
        "DATASETPATH = './dataset'\n",
        "DATA_CONTROL = os.path.join(DATASETPATH , 'Controls')  # '/content/drive/MyDrive/Parkinson/dataset/Controls'\n",
        "DATA_PD = os.path.join(DATASETPATH , 'PD')             # '/content/drive/MyDrive/Parkinson/dataset/Controls'\n",
        "\n",
        "\n",
        "# CSV INFO(FW,BW 개수 및 경로) 저장 경로\n",
        "SAVEPATH = './csvinfo.csv'                             # /content/drive/MyDrive/Parkinson/csvinfo.csv"
      ],
      "metadata": {
        "id": "eGCUw7y6IBNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 39개 관측 센서 위치\n",
        "- 머리 -> 몸통 -> 다리 -> 발\n",
        "- 앞면 왼,오 -> 뒷면 왼,오 순서로!"
      ],
      "metadata": {
        "id": "uqsXUhAhSk0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MARKERS = ['LFHD', 'RFHD', 'LBHD', 'RBHD', 'C7', 'LSHO', 'RSHO', 'CLAV', 'RBAK',\n",
        "           'LUPA', 'RUPA', 'STRN', 'T10', 'LELB', 'RELB', 'LFRM', 'RFRM',\n",
        "           'LWRA', 'RWRA', 'LWRB', 'RWRB', 'LFIN', 'RFIN', 'LASI', 'RASI',\n",
        "           'LPSI', 'RPSI', 'LTHI', 'RTHI', 'LKNE', 'RKNE', 'LTIB', 'RTIB',\n",
        "           'LANK', 'RANK', 'LTOE', 'RTOE', 'LHEE', 'RHEE']\n",
        "len(MARKERS)"
      ],
      "metadata": {
        "id": "bhAOC05MK0ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 추출\n",
        "- Subframe 열 제거\n",
        "- 두번째 행의 측정 단위를 보면 369개의 측정값 중 1/3은 거리(mm), 1/3은 속도(mm/s), 나머지 1/3은 가속도(mm/s^2)임을 알 수 있다. \\\n",
        "따라서, 속도와 가속도 데이터를 제외하고 추출한다.\n",
        "- CentreOfMass, CentreOfMasFloor, TURN_MARKER 제거\n",
        "- 컬럼 순서 재배열 (머리 - 상체 - 하체 - 발)\n",
        "\n",
        "- 총 컬럼 수: Frame + 마커 39개 * 3 (X,Y,Z) = 118개\n",
        "- 저장 파일명: PREP_이니셜_FW/BW1-3.csv \\\n",
        "  (Trial 번호 1,2,3으로 다시 넘버링 함)"
      ],
      "metadata": {
        "id": "d3WBdcJSLgbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_data_from_raw(target_cate:str, target_file:str):\n",
        "    \"\"\"\n",
        "    target_cate: 'Controls' or 'PD'\n",
        "    target_file: '이니셜_FW1.csv', '이니셜_FW_01.csv', 'KangYK_FW01.csv'\n",
        "    \n",
        "    >> Save as './dataset/{소속}/PREP_{이니셜}_{FW/BW}{1~3}.csv' after preprocessing\n",
        "    \"\"\"\n",
        "    print(f\"\\n======= Current Preprocessing: {target_file} =======\")\n",
        "\n",
        "    # ============  데이터 추출  ===============\n",
        "    # 첫 두 행(Trajectories 정보) 제외하고 읽기\n",
        "    # 일단 Frame을 인덱스로 설정\n",
        "    target_path = RAW_PD if target_cate == 'PD' else RAW_CONTROL\n",
        "    df = pd.read_csv(os.path.join(target_path, target_file), skiprows=2, index_col=0)\n",
        "    \n",
        "    # Sub Frame 제거\n",
        "    df.drop(columns=df.columns[df.iloc[0]=='Sub Frame'], inplace=True)  \n",
        "\n",
        "    # 단위가 mm인 데이터 추출\n",
        "    df = df[df.columns[df.iloc[1]=='mm']]  # 39*3=117개 넘으면 Centre 포함\n",
        "    # print(f\"[Before] Number of Markers: {df.shape[1] // 3}\")  # 마커 개수 확인\n",
        "\n",
        "    # 컬럼명 변경: '이니셜:마커' or 'Unnamed: n' -> '마커명_X', '마커명_Y', '마커명_Z'\n",
        "    col_names = []\n",
        "    observed_markers = []\n",
        "    for i, col in enumerate(df.columns):\n",
        "        if i % 3 == 0:\n",
        "            placement = col.split(':')[1]\n",
        "            observed_markers.append(placement)\n",
        "        col_names.append(placement + '_' + df.iloc[0,i])  # LFHD_X, LFHD_Y, LFHD_Z, ...\n",
        "    df.columns = col_names\n",
        "    \n",
        "    # XYZ, 단위(mm) 행 제거\n",
        "    df = df.iloc[2:]\n",
        "\n",
        "    # CentreOfMass, CentreOfMasFloor, TURN_MARKER 제거\n",
        "    df = df.loc[:, [col for col in df.columns if col.split('_')[0] in MARKERS]]\n",
        "    \n",
        "    # 39개 마커 중 빠진 게 있으면 Null 컬럼으로 추가\n",
        "    if df.shape[1] != 117:\n",
        "        missing = set(MARKERS) - set(observed_markers)\n",
        "        print(f\"Only {df.shape[1]} columns. Missing markers = {missing}\")\n",
        "        for miss in missing:\n",
        "            df[miss + '_X'] = np.nan\n",
        "            df[miss + '_Y'] = np.nan\n",
        "            df[miss + '_Z'] = np.nan\n",
        "\n",
        "    assert df.shape[1] == 117\n",
        "\n",
        "    # 마커 순서 재배열\n",
        "    df = df.loc[:, [m + '_' + axis for m in MARKERS for axis in ['X','Y','Z']]]\n",
        "\n",
        "    # Frame을 인덱스에서 컬럼으로 변경\n",
        "    df['Frame'] = df.index\n",
        "    df = df[[df.columns[-1]] + df.columns[:-1].to_list()] # Frame 컬럼을 맨 앞으로\n",
        "    df.reset_index(drop=True, inplace=True)               # 인덱스 리셋 (0부터 시작)\n",
        "    assert df.shape[1] == 118\n",
        "\n",
        "\n",
        "    # =============  Prep 후 csv로 저장  =============\n",
        "    # 저장할 때 파일명 포맷 통일: 'PREP_이니셜_FW/BW1~3.csv'\n",
        "    splitted = target_file[:-4].split('_')\n",
        "    splitted.insert(0, 'PREP')\n",
        "    \n",
        "    if len(splitted) == 4:    # PREP_이니셜_FW_1 인 경우 (언더바 하나 더 있음)\n",
        "        splitted[2] = splitted[2] + str(int(splitted[-1]))\n",
        "        splitted = splitted[:3]\n",
        "    assert len(splitted) == 3\n",
        "\n",
        "    if len(splitted[-1]) > 3: # PREP_이니셜_FW01 인 경우 (숫자에 0 포함)\n",
        "        splitted[-1] = splitted[-1][:2] + str(int(splitted[-1][2:]))\n",
        "\n",
        "    # Trial Re-numbering: 124, 234, 134 등 제각각이므로 1,2,3으로 통일\n",
        "    save_path = DATA_PD if target_cate == 'PD' else DATA_CONTROL\n",
        "    raw_files = glob.glob(os.path.join(target_path, f\"{splitted[1]}_{splitted[-1][:2]}*.csv\"))\n",
        "    prep_files = glob.glob(os.path.join(save_path, f\"PREP_{splitted[1]}_{splitted[-1][:2]}*.csv\"))\n",
        "    if len(prep_files) < len(raw_files):\n",
        "        splitted[-1] = splitted[-1][:2] + str(len(prep_files) + 1)\n",
        "        df.to_csv(os.path.join(save_path, '_'.join(splitted) + '.csv'), encoding='utf-8', index=False)\n",
        "    else:\n",
        "        print(f\"\\n** 3 prep files of {splitted[1]}_{splitted[2][:2]} already exist!! **\")\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "plWE_0V_Cl9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prep_data(rawdata_path):\n",
        "    category = rawdata_path.split('/')[-1]\n",
        "    for filename in sorted(os.listdir(rawdata_path)):\n",
        "        prep_data_from_raw(category, filename)"
      ],
      "metadata": {
        "id": "ViApWftiI9ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing 수행 (Controls)"
      ],
      "metadata": {
        "id": "OpTrTL9YD_4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prep 수행 전, 저장할 폴더의 존재여부 및 비어있는지 확인!!\n",
        "# trial numbering 할 때 중복을 체크하지 않으므로 무조건 비어있는 상태에서 처음부터 해야함..\n",
        "if not os.path.exists(DATASETPATH):\n",
        "    os.mkdir(DATASETPATH)\n",
        "if not os.path.exists(DATA_CONTROL):\n",
        "    os.mkdir(DATA_CONTROL)\n",
        "\n",
        "assert len(os.listdir(DATA_CONTROL)) == 0\n",
        "generate_prep_data(RAW_CONTROL)"
      ],
      "metadata": {
        "id": "7papo252KuFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"[Controls] Raw: {len(os.listdir(RAW_CONTROL))} -> Prep: {len(os.listdir(DATA_CONTROL))}\")\n",
        "assert len(os.listdir(RAW_CONTROL)) == len(os.listdir(DATA_CONTROL))"
      ],
      "metadata": {
        "id": "X3JV8Y6eKWn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing 수행 (PD)"
      ],
      "metadata": {
        "id": "g9aEwSxcFQfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prep 수행 전, 저장할 폴더의 존재여부 및 비어있는지 확인!!\n",
        "if not os.path.exists(DATASETPATH):\n",
        "    os.mkdir(DATASETPATH)\n",
        "if not os.path.exists(DATA_PD):\n",
        "    os.mkdir(DATA_PD)\n",
        "\n",
        "assert len(os.listdir(DATA_PD)) == 0\n",
        "generate_prep_data(RAW_PD)"
      ],
      "metadata": {
        "id": "hSAhgWRCAGeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"[PD] Raw: {len(os.listdir(RAW_PD))} -> Prep: {len(os.listdir(DATA_PD))}\")\n",
        "assert len(os.listdir(RAW_PD)) == len(os.listdir(DATA_PD))"
      ],
      "metadata": {
        "id": "od4nT6W5HBEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CSV 파일 정보 취합\n",
        "- `path` : 파일경로  (`./dataset/소속/PREP_이름_FW1.csv`)\n",
        "- `category` : 소속  (`Controls` or `PD`)\n",
        "- `name` : 환자 이니셜/이름 (`BGH` or `KimYC`)\n",
        "- `trial` : 보행 실험 종류 및 횟수 (`FW1~3` or `BW1~3`)\n",
        "- `frame length` : 전체 프레임 수\n",
        "- `remove` : 결측률이 0.5 이상이면 `True`, 0.5 미만이면 `False`\n",
        "\n",
        "- `LFHD` ~ `RHEE` : 각 마커별 NULL인 프레임 번호를 `시작:끝`의 범위 또는 `프레임값`으로 표현\\\n",
        "여러 개의 결측 구간을 공백으로 구분 --> \"701:705 708\""
      ],
      "metadata": {
        "id": "6jHLfTTJdiTr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_null_from_prep(target_cate, direction):\n",
        "    target_path = DATA_CONTROL if target_cate == 'Controls' else DATA_PD\n",
        "    target_files = [f for f in os.listdir(target_path) if direction in f.split('_')[-1]]\n",
        "    \n",
        "    # 해당 csv의 NULL 정보를 저장할 데이터프레임\n",
        "    df_info = pd.DataFrame(index=range(len(target_files)),\n",
        "                           columns=[['path','category','name','trial','frame length','remove'] + MARKERS])\n",
        "    df_info['category'] = target_path.split('/')[-1]\n",
        "\n",
        "    # 해당 소속의 모든 csv 파일에 대해 NULL 탐색\n",
        "    for id, filename in enumerate(sorted(target_files)):\n",
        "        path = os.path.join(target_path, filename)     # ./dataset/소속/PREP_이니셜_FW/BW1~3.csv\n",
        "        _, name, trial = filename[:-4].split('_')      # [PREP, 이니셜, FW/BW1~3]\n",
        "        \n",
        "        # 데이터 불러오기\n",
        "        df = pd.read_csv(path, index_col=0)            # Frame을 인덱스로 설정\n",
        "        df_info.loc[id, ['path','name','trial','frame length']] = [path, name, trial, df.shape[0]]\n",
        "\n",
        "        # NULL 찾기: X,Y,Z 컬럼이 똑같이 결측이므로 '마커멍_X'만 본다.\n",
        "        remove = False\n",
        "        for col in df.columns[::3]:\n",
        "            if df[col].isna().sum() == 0: continue     # 결측값이 없으면 스킵\n",
        "            \n",
        "            # ===== 마커에 결측값이 존재하는 경우 =====\n",
        "            null = df.loc[df[col].isna()].index.values # NULL 프레임 번호 리스트\n",
        "\n",
        "            # 전체 프레임 중 NULL 프레임 비율이 0.5 이상이면 해당 csv 파일은 제거 대상이다.\n",
        "            if len(null) / len(df) >= 0.5:\n",
        "                remove = True\n",
        "            \n",
        "            # 띄엄띄엄 결측이므로 NULL 프레임 구간들의 범위 저장 ['시작:끝', ..., '시작:끝']\n",
        "            null = np.append(null, np.array([-1]))     # 인덱스 에러 방지용 더미값 -1 추가     \n",
        "            null_range = []                            # NULL 프레임 범위 저장할 리스트\n",
        "            i,j = 0,1                                  # i: 시작, j: 끝\n",
        "            while j < len(null):\n",
        "                while null[j] - null[j-1] == 1 and j < len(null)-1:\n",
        "                    j += 1   # 프레임 값이 불연속일 때까지 끝 인덱스(j)를 1씩 증가\n",
        "                \n",
        "                if i == j-1: # 프레임 하나만 NULL인 경우 한 점만 저장\n",
        "                    null_range.append(str(null[i])) \n",
        "                else:        # NULL 프레임의 구간 '시작:끝' 저장\n",
        "                    null_range.append(str(null[i]) + ':' + str(null[j-1]))\n",
        "\n",
        "                i = j        # 다음 구간 시작점 = 이전 구간 끝점 직후\n",
        "                j = i+1      # 다시 j를 끝점으로 하여 다음 다음 구간 탐색\n",
        "            \n",
        "            # 해당 마커명에 결측 구간에 대한 문자열 저장 -> '시작:끝 포인트 시작:끝 ...'\n",
        "            df_info.loc[id, col[:-2]] = ' '.join(null_range) \n",
        "\n",
        "        # 모든 마커에 대한 결측 탐색이 끝나면 해당 csv 파일의 제거 여부를 저장\n",
        "        df_info.loc[id, 'remove'] = remove\n",
        "    \n",
        "    return df_info"
      ],
      "metadata": {
        "id": "a2iDqosVdocf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_csv_info_table():\n",
        "    df_Controls_BW = find_null_from_prep('Controls', 'BW')\n",
        "    df_Controls_FW = find_null_from_prep('Controls', 'FW')\n",
        "\n",
        "    df_PD_BW = find_null_from_prep('PD', 'BW')\n",
        "    df_PD_FW = find_null_from_prep('PD', 'FW')\n",
        "\n",
        "    return pd.concat([df_Controls_BW, df_Controls_FW, df_PD_BW, df_PD_FW], ignore_index=True)"
      ],
      "metadata": {
        "id": "63NsQwkkdoj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_info = generate_csv_info_table()\n",
        "df_info"
      ],
      "metadata": {
        "id": "K7rujQJ4donO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_info.to_csv(SAVEPATH, encoding='utf-8', index=False)"
      ],
      "metadata": {
        "id": "O3SyfXRGdosW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EBA0lR0Adoy5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}