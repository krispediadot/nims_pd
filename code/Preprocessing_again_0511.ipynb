{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing_again_0511.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "fdEH120r2MZh"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "so_Bbg2JEnxx"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Parkinson"
      ],
      "metadata": {
        "id": "5z-qe7YLE4Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "pd.options.display.max_rows = 100\n",
        "pd.options.display.max_columns = 50"
      ],
      "metadata": {
        "id": "1FmJ7zIYFFUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rawdata 저장 경로\n",
        "RAWDATAPATH = os.path.join(os.getcwd(), 'Rawdata')\n",
        "RAW_CONTROL = os.path.join(RAWDATAPATH , 'Controls')  # '/content/drive/MyDrive/Parkinson/Rawdata/Controls'\n",
        "RAW_PD = os.path.join(RAWDATAPATH, 'PD')              # '/content/drive/MyDrive/Parkinson/Rawdata/PD'\n",
        "\n",
        "\n",
        "# 추출 후 저장할 경로\n",
        "DATASETPATH = os.path.join(os.getcwd(), 'dataset')           \n",
        "DATA_CONTROL = os.path.join(DATASETPATH , 'Controls')    # '/content/drive/MyDrive/Parkinson/dataset/Controls'\n",
        "DATA_PD = os.path.join(DATASETPATH , 'PD')               # '/content/drive/MyDrive/Parkinson/dataset/Controls'\n",
        "\n",
        "\n",
        "# CSV INFO(FW,BW 개수 및 경로) 저장 경로\n",
        "SAVEPATH = os.path.join(DATASETPATH, 'patients.csv')"
      ],
      "metadata": {
        "id": "eGCUw7y6IBNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 39개 관측 센서 위치\n",
        "- 머리 -> 몸통 -> 다리 -> 발\n",
        "- 앞면 왼,오 -> 뒷면 왼,오 순서로!"
      ],
      "metadata": {
        "id": "uqsXUhAhSk0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MARKERS = ['LFHD', 'RFHD', 'LBHD', 'RBHD', 'C7', 'LSHO', 'RSHO', 'CLAV', 'RBAK',\n",
        "           'LUPA', 'RUPA', 'STRN', 'T10', 'LELB', 'RELB', 'LFRM', 'RFRM',\n",
        "           'LWRA', 'RWRA', 'LWRB', 'RWRB', 'LFIN', 'RFIN', 'LASI', 'RASI',\n",
        "           'LPSI', 'RPSI', 'LTHI', 'RTHI', 'LKNE', 'RKNE', 'LTIB', 'RTIB',\n",
        "           'LANK', 'RANK', 'LTOE', 'RTOE', 'LHEE', 'RHEE']\n",
        "len(MARKERS)"
      ],
      "metadata": {
        "id": "bhAOC05MK0ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 추출\n",
        "- Subframe 열 제거\n",
        "- 두번째 행의 측정 단위를 보면 369개의 측정값 중 1/3은 거리(mm), 1/3은 속도(mm/s), 나머지 1/3은 가속도(mm/s^2)임을 알 수 있다. \\\n",
        "따라서, 속도와 가속도 데이터를 제외하고 추출한다.\n",
        "- CentreOfMass_XYZ, CentreOfMasFloor_XYZ 제거\n",
        "- 컬럼 순서 재배열 (머리 - 상체 - 하체 - 발)\n",
        "\n",
        "- 총 컬럼 수: Frame + 마커 39개 * 3 (X,Y,Z) = 118개\n",
        "- 저장 파일명: PREP_이니셜_FW/BW1-3.csv \\\n",
        "  (Trial 번호 1,2,3으로 다시 넘버링 함)"
      ],
      "metadata": {
        "id": "d3WBdcJSLgbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_data_from_raw(target_cate:str, target_file:str):\n",
        "    \"\"\"\n",
        "    target_cate: 'Controls' or 'PD'\n",
        "    target_file: '이니셜_FW1.csv', '이니셜_FW_01.csv', 'KangYK_FW01.csv'\n",
        "    \n",
        "    >> Save as './dataset/{소속}/PREP_{이니셜}_{FW/BW}{1~3}.csv' after preprocessing\n",
        "    \"\"\"\n",
        "    print(f\"\\n======= Current Preprocessing File: {target_file} =======\")\n",
        "\n",
        "    # ============  데이터 추출  ===============\n",
        "    # 첫 두 행(Trajectories 정보) 제외하고 읽기\n",
        "    # 일단 Frame을 인덱스로 설정\n",
        "    target_path = RAW_PD if target_cate == 'PD' else RAW_CONTROL\n",
        "    df = pd.read_csv(os.path.join(target_path, target_file), skiprows=2, index_col=0)\n",
        "    \n",
        "    # Sub Frame 제거\n",
        "    df.drop(columns=df.columns[df.iloc[0]=='Sub Frame'], inplace=True)  \n",
        "\n",
        "    # 단위가 mm인 데이터 추출\n",
        "    df = df[df.columns[df.iloc[1]=='mm']]  # 39*3=117개 넘으면 Centre 포함\n",
        "    print(f\"[Before] Number of Markers: {df.shape[1] // 3}\")  # 마커 개수 확인\n",
        "\n",
        "    # 컬럼명 변경: '이니셜:마커' or 'Unnamed: n' -> '마커명_X', '마커명_Y', '마커명_Z'\n",
        "    col_names = []\n",
        "    for i, col in enumerate(df.columns):\n",
        "        if i % 3 == 0:\n",
        "            placement = col.split(':')[1]\n",
        "        col_names.append(placement + '_' + df.iloc[0,i])  # LFHD_X, LFHD_Y, LFHD_Z, ...\n",
        "    df.columns = col_names\n",
        "    \n",
        "    # XYZ, 단위(mm) 행 제거\n",
        "    df = df.iloc[2:]\n",
        "\n",
        "    # CentreOfMass, CentreOfMasFloor, TURN_MARKER 제거\n",
        "    df = df.loc[:, [col for col in df.columns if col.split('_')[0] in MARKERS]]\n",
        "    assert df.shape[1] == 117\n",
        "    # print(f\"[After] Number of Markers: {len(df.columns) // 3} (Goal: 39)\")\n",
        "\n",
        "    # 마커 순서 재배열\n",
        "    df = df.loc[:, [m + '_' + axis for m in MARKERS for axis in ['X','Y','Z']]]\n",
        "\n",
        "    # Frame을 인덱스에서 컬럼으로 변경\n",
        "    df['Frame'] = df.index\n",
        "    df = df[[df.columns[-1]] + df.columns[:-1].to_list()] # Frame 컬럼을 맨 앞으로\n",
        "    df.reset_index(drop=True, inplace=True)               # 인덱스 리셋 (0부터 시작)\n",
        "    assert df.shape[1] == 118\n",
        "    # print(f\"[FINAL] Number of columns: {df.shape[1]} (Goal: 118)\")\n",
        "\n",
        "\n",
        "    # =============  Prep 후 csv로 저장  =============\n",
        "    # 저장할 때 파일명 포맷 통일: 'PREP_이니셜_FW/BW1~3.csv'\n",
        "    splitted = target_file[:-4].split('_')\n",
        "    splitted.insert(0, 'PREP')\n",
        "    \n",
        "    if len(splitted) == 4:    # PREP_이니셜_FW_1 인 경우 (언더바 하나 더 있음)\n",
        "        splitted[2] = splitted[2] + str(int(splitted[-1]))\n",
        "        splitted = splitted[:3]\n",
        "    assert len(splitted) == 3\n",
        "\n",
        "    if len(splitted[-1]) > 3: # PREP_이니셜_FW01 인 경우 (숫자에 0 포함)\n",
        "        splitted[-1] = splitted[-1][:2] + str(int(splitted[-1][2:]))\n",
        "\n",
        "    # Trial Re-numbering: 124, 234, 134 등 제각각이므로 1,2,3으로 통일\n",
        "    save_path = DATA_PD if target_cate == 'PD' else DATA_CONTROL\n",
        "    raw_files = glob.glob(os.path.join(target_path, f\"{splitted[1]}_{splitted[-1][:2]}*.csv\"))\n",
        "    prep_files = glob.glob(os.path.join(save_path, f\"PREP_{splitted[1]}_{splitted[-1][:2]}*.csv\"))\n",
        "    if len(prep_files) < len(raw_files):\n",
        "        splitted[-1] = splitted[-1][:2] + str(len(prep_files) + 1)\n",
        "        df.to_csv(os.path.join(save_path, '_'.join(splitted) + '.csv'), encoding='utf-8', index=False)\n",
        "    else:\n",
        "        print(f\"\\n** 3 prep files of {splitted[1]}_{splitted[2][:2]} already exist!! **\")\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "plWE_0V_Cl9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prep_data(rawdata_path):\n",
        "    category = rawdata_path.split('/')[-1]\n",
        "    for filename in sorted(os.listdir(rawdata_path)):\n",
        "        # Exception\n",
        "        if category == 'PD' and filename == 'KMS_FW3.csv': continue  # 원본 자체에 마커가 38개.. RFHD 누락!\n",
        "        \n",
        "        name, trial = filename.split('_')[:2]\n",
        "        save_path = DATA_PD if category == 'PD' else DATA_CONTROL\n",
        "        # if len(glob.glob(os.path.join(save_path, f\"PREP_{name}_{trial[:2]}*.csv\"))) == 3: \n",
        "        #     continue  # 이미 Prep한 파일이 3개 있으면 패스한다.\n",
        "        \n",
        "        prep_data_from_raw(category, filename)"
      ],
      "metadata": {
        "id": "ViApWftiI9ZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Preprocessing 수행 (Controls)"
      ],
      "metadata": {
        "id": "OpTrTL9YD_4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prep 수행 전, 저장할 폴더의 존재여부 및 비어있는지 확인!!\n",
        "# trial numbering 할 때 중복여부를 체크하지 않으므로 무조건 비어있는 상태에서 처음부터 해야함...\n",
        "if not os.path.exists(DATASETPATH):\n",
        "    os.mkdir(DATASETPATH)\n",
        "if not os.path.exists(DATA_CONTROL):\n",
        "    os.mkdir(DATA_CONTROL)\n",
        "\n",
        "assert len(os.listdir(DATA_CONTROL)) == 0\n",
        "generate_prep_data(RAW_CONTROL)"
      ],
      "metadata": {
        "id": "7papo252KuFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"[Controls] Raw: {len(os.listdir(RAW_CONTROL))} -> Prep: {len(os.listdir(DATA_CONTROL))}\")\n",
        "assert len(os.listdir(RAW_CONTROL)) == len(os.listdir(DATA_CONTROL))"
      ],
      "metadata": {
        "id": "X3JV8Y6eKWn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# control_names = set(f.split('_')[:2][0] for f in sorted(os.listdir(RAW_CONTROL)))\n",
        "# len(control_names)"
      ],
      "metadata": {
        "id": "YgXMcSs1LV0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Preprocessing 수행 (PD)"
      ],
      "metadata": {
        "id": "g9aEwSxcFQfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prep 수행 전, 저장할 폴더의 존재여부 및 비어있는지 확인!!\n",
        "if not os.path.exists(DATASETPATH):\n",
        "    os.mkdir(DATASETPATH)\n",
        "if not os.path.exists(DATA_PD):\n",
        "    os.mkdir(DATA_PD)\n",
        "\n",
        "assert len(os.listdir(DATA_PD)) == 0\n",
        "generate_prep_data(RAW_PD)"
      ],
      "metadata": {
        "id": "hSAhgWRCAGeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n[PD] Raw: {len(os.listdir(RAW_PD))} -> Prep: {len(os.listdir(DATA_PD))}\")\n",
        "assert len(os.listdir(RAW_PD)) - 1 == len(os.listdir(DATA_PD))"
      ],
      "metadata": {
        "id": "od4nT6W5HBEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "M0UPW_kqYozN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 환자 정보 취합\n",
        "\n",
        "- 환자 이름: 영문 이니셜\n",
        "- 소속: PD, Controls\n",
        "- FW, BW 개수\n",
        "- FW, BW 파일 위치: `./dataset/{소속}` (Prep 후)"
      ],
      "metadata": {
        "id": "FHkjOn3pc4dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_csv_info(target_cate: str) -> pd.DataFrame:\n",
        "    \n",
        "    \"\"\"\n",
        "    target_cate: 'Controls' or 'PD'\n",
        "    \"\"\"\n",
        "\n",
        "    # 실험 참여자별 FW, BW 파일 개수 세기 & 파일 경로 저장\n",
        "    cntFW = defaultdict(int)\n",
        "    cntBW = defaultdict(int)\n",
        "    pathFW = defaultdict(list)\n",
        "    pathBW = defaultdict(list)\n",
        "\n",
        "    target_path = DATA_CONTROL if target_cate == 'Controls' else DATA_PD\n",
        "\n",
        "    for filename in sorted(os.listdir(target_path)):\n",
        "        _, name, trial = filename[:-4].split('_')  # [PREP, 이니셜, trial]\n",
        "        \n",
        "        if trial[:2] == 'FW':\n",
        "            cntFW[name] += 1\n",
        "            pathFW[name].append('/'.join(['.', DATASETPATH.split('/')[-1], target_cate, filename]))\n",
        "        else:  #  trial[:2] == 'BW'\n",
        "            cntBW[name] += 1\n",
        "            pathBW[name].append('/'.join(['.', DATASETPATH.split('/')[-1], target_cate, filename]))\n",
        "    \n",
        "    # FW만 있는 환자는 BW 개수를 0으로 입력\n",
        "    for k in cntFW.keys():\n",
        "        if k not in cntBW.keys():\n",
        "            cntBW[k] = 0\n",
        "            pathBW[k] = []\n",
        "    \n",
        "    # 딕셔너리 정렬: 키 값(이니셜) 기준\n",
        "    cntFW = dict(sorted(cntFW.items()))\n",
        "    cntBW = dict(sorted(cntBW.items()))\n",
        "    pathFW = dict(sorted(pathFW.items()))\n",
        "    pathBW = dict(sorted(pathBW.items()))\n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    df['Patient'] = list(cntFW.keys())\n",
        "    df['Category'] = target_cate\n",
        "    df['cntFW'] = list(cntFW.values())\n",
        "    df['cntBW'] = list(cntBW.values())\n",
        "    df['pathFW'] = pathFW.values()\n",
        "    df['pathBW'] = pathBW.values()\n",
        "    \n",
        "    return df"
      ],
      "metadata": {
        "id": "RofDkLITc7e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_csv_info_table(save_path):\n",
        "    \"\"\"\n",
        "    Create and save patients FW & BW count information table\n",
        "    save path = ./dataset/patients.csv\n",
        "    \"\"\"\n",
        "\n",
        "    df_PD = get_csv_info('PD')\n",
        "    df_Controls = get_csv_info('Controls')\n",
        "    df_info = pd.concat([df_PD, df_Controls], ignore_index=True)\n",
        "    df_info.to_csv(save_path, encoding='utf-8', index=False)\n",
        "    # return df_info"
      ],
      "metadata": {
        "id": "VQg-r5OHdB2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_csv_info_table(SAVEPATH)"
      ],
      "metadata": {
        "id": "WisQsJGThldc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 수진쌤 코드 터미널 실행"
      ],
      "metadata": {
        "id": "fdEH120r2MZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/NIMS/Parkinson/code/utils"
      ],
      "metadata": {
        "id": "L5vN-xy22ZyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!bash python preprocessor.py --debug=true"
      ],
      "metadata": {
        "id": "WiKndH9U2PQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "c28Fuj2L2kp8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}